{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8638493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Training samples: 4457\n",
      "Testing samples: 1115\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Load the preprocessed data\n",
    "train_df = pd.read_csv('../../data/processed/train.csv')\n",
    "test_df = pd.read_csv('../../data/processed/test.csv')\n",
    "\n",
    "# Handle potential NaN values in 'cleaned_message' that might arise from preprocessing\n",
    "train_df['cleaned_message'] = train_df['cleaned_message'].fillna('')\n",
    "test_df['cleaned_message'] = test_df['cleaned_message'].fillna('')\n",
    "\n",
    "\n",
    "X_train = train_df['cleaned_message']\n",
    "y_train = train_df['label']\n",
    "X_test = test_df['cleaned_message']\n",
    "y_test = test_df['label']\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b22dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF vectorization complete.\n",
      "Shape of TF-IDF training matrix: (4457, 3000)\n"
     ]
    }
   ],
   "source": [
    "# --- Researcher's Justification ---\n",
    "# TF-IDF is chosen for its effectiveness and interpretability in text classification.\n",
    "# We initialize the vectorizer and `fit` it ONLY on the training data.\n",
    "# This prevents data leakage from the test set, a fundamental principle of ML evaluation.\n",
    "# `max_features` is set to prevent an overly large vocabulary, which helps with\n",
    "# model generalization and reduces computational load.\n",
    "# ------------------------------------\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "\n",
    "# Fit on training data and transform it\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Only transform the test data using the already-fitted vectorizer\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF vectorization complete.\")\n",
    "print(f\"Shape of TF-IDF training matrix: {X_train_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82508a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centralized Logistic Regression model trained.\n"
     ]
    }
   ],
   "source": [
    "# --- Researcher's Justification ---\n",
    "# Logistic Regression is a great baseline: it's lightweight, fast, and highly interpretable.\n",
    "# `class_weight='balanced'` is used to counteract the class imbalance. It automatically\n",
    "# adjusts weights inversely proportional to class frequencies in the input data.\n",
    "# This makes the model pay more attention to the minority class (spam).\n",
    "# `random_state` ensures reproducibility of results.\n",
    "# ------------------------------------\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"Centralized Logistic Regression model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "451092a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Centralized Baseline Performance ---\n",
      "Accuracy: 0.9812\n",
      "Precision: 0.9384\n",
      "Recall: 0.9195\n",
      "F1-Score: 0.9288\n",
      "\n",
      "--- Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Ham (0)       0.99      0.99      0.99       966\n",
      "    Spam (1)       0.94      0.92      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# --- Researcher's Justification ---\n",
    "# We compute a full suite of metrics.\n",
    "# - Accuracy: Overall correctness. Can be misleading with imbalanced data.\n",
    "# - Precision (for spam=1): Of all messages predicted as spam, how many were actually spam? (Measures false positives)\n",
    "# - Recall (for spam=1): Of all actual spam messages, how many did we catch? (Measures false negatives)\n",
    "# - F1-Score: The harmonic mean of precision and recall, providing a single, robust metric for imbalanced classes.\n",
    "# The classification report provides a clean summary of these key metrics.\n",
    "# ------------------------------------\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"--- Centralized Baseline Performance ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham (0)', 'Spam (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a5755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
